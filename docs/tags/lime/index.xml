<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LIME on Institute of Infomation Systems at HU-Berlin</title>
    <link>https://humboldt-wi.github.io/blog/tags/lime/</link>
    <description>Recent content in LIME on Institute of Infomation Systems at HU-Berlin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Feb 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://humboldt-wi.github.io/blog/tags/lime/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Opening the black box of machine learning</title>
      <link>https://humboldt-wi.github.io/blog/research/information_systems_1819/openingtheblackbox/</link>
      <pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://humboldt-wi.github.io/blog/research/information_systems_1819/openingtheblackbox/</guid>
      <description>Authors: Christopher Ketzler, Stefan Grosse, Raiber Alkurdi Motivation The development of machine learning or deep learning (ML/DL) models which provides the user to have a decision to a specific problem has progressed enormously in the last years. The emergence of better computer hardware and therefore software, and the collecting of big data leads to more and more complicated algorithms. If these algorithms are no more understandable by average humans in terms of what are they doing or why they give a certain decision, we call them black-boxes.</description>
    </item>
    
  </channel>
</rss>